% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functional_ASE.R
\name{fASE_tuning}
\alias{fASE_tuning}
\title{Perform (parallelized) hyperparameter tuning for network embeddings.}
\usage{
fASE_tuning(
  spline_no_range,
  embedding_dim_range,
  tuning_method = "heuristic",
  adjacency_tensor,
  spline_order = 4,
  batch_size = NULL,
  kernel_scale = FALSE,
  timestamp_vec = NULL,
  scalable_method = TRUE,
  scalable_dim = 20,
  scalable_power = 6,
  iteration_step = 2000,
  epsilon = 1e-05,
  parallel = FALSE
)
}
\arguments{
\item{spline_no_range}{Numeric vector, the range for tuning the number of B-splines.}

\item{embedding_dim_range}{Numeric vector, the range for tuning the dimension of latent functions.}

\item{tuning_method}{String, if tuning_method = "heuristic" then alternating optimizing the two hyperparameters, else if tuning_method = "grid" using the grid search.}

\item{adjacency_tensor}{an n*n*T array where each slice is a snapshot of the dynamic network.}

\item{spline_order}{(optional) scalar. the polynomial order of B-spline basis, default 4}

\item{batch_size}{(optional) scalar. the size of batches in mini-batch algorithm, default max(50,floor(n/20))}

\item{kernel_scale}{(optional) scalar. the scaled parameter in the kernel used for smoothing, default two times the quartile of the time intervals.}

\item{timestamp_vec}{(optional) vector. the observed time points of observation, default 1:T.}

\item{scalable_method}{(optional) logical. whether to use the random-projection based SVD and mini-batch methods, default TRUE.}

\item{scalable_dim}{(optional) scalar. the dimension of random projection if scalable_method = TRUE, default 20.}

\item{scalable_power}{(optional) scalar. the time of power iterations in power method when using the random-projection based SVD, default 6.}

\item{iteration_step}{(optional) scalar. the number of maximal iteration steps for the gradient algorithm, default 2500.}

\item{epsilon}{(optional) scalar. the stopping criterion for the gradient algorithm, default 1e-6.}

\item{parallel}{(optional) logical. whether to parallel when tuning hyperparameters, defult TRUE.}
}
\value{
a matrix containing three columns, corresponding to spline numbers, embedding dimensions and the resulting generalized cross-validation criterion.
}
\description{
Perform (parallelized) hyperparameter tuning for network embeddings.
}
\examples{
\donttest{
ER_generation <- function(n, p) {
  adjacency_matrix <- matrix(0, nrow = n, ncol = n)
  for (i in 2:n) {
    for (j in 1:(i - 1)) {
      adjacency_matrix[i, j] <- sample(c(0, 1), size = 1, prob = c(1 - p, p))
    }
    adjacency_matrix[i, i] <- 0.5
  }
  adjacency_matrix + t(adjacency_matrix)
}
set.seed(10)
n_nodes <- 10
T <- 10
p <- 0.2
dynamic_adjacency <- c()
dynamic_network_adjacency <- array(0, dim = c(n_nodes, n_nodes, T))
for (t in 1:T) {
  adj <- ER_generation(n_nodes, p)
  dynamic_adjacency <- c(dynamic_adjacency, list(list(adj)))
  dynamic_network_adjacency[, , t] <- adj
}
tuning_sim1 <- fASE_tuning(5:8, 4:5, tuning_method = "heuristic", adjacency_tensor = dynamic_network_adjacency, spline_order = 4, batch_size = NULL, kernel_scale = FALSE, timestamp_vec = NULL, scalable_method = TRUE, scalable_dim = 30, scalable_power = 6, iteration_step = 2500, epsilon = 1e-3)
tuning_parameter1 <- get_tuning(tuning_sim1)
}
}
